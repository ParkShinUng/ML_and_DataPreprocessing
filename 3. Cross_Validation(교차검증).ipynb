{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation(교차검증)\n",
    "* 과적합(Overfitting)을 방지해서 예측도를 높히기 위한 방법들\n",
    "* 1. K-Fold\n",
    "* 2. Stratified K-Fold\n",
    "* 3. cross_val_score()\n",
    "* 4. GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.K-Fold\n",
    "* 모든 데이터가 최소 한번은 검증 데이터셋으로 사용되도록 한다.\n",
    "* 1) Fold 세트 설정\n",
    "* 2) for 루프로 학습/검증 데이터 추출 및 학습\n",
    "* 3) Fold 세트별로 예측 성능 평균을 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "붓꽃 데이터 세트 크기  (150, 4) (150,)\n",
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "train \n",
      " [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test \n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "train \n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test \n",
      " [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "train \n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test \n",
      " [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "train \n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test \n",
      " [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "train \n",
      " [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "test \n",
      " [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "print(iris.keys())\n",
    "features = iris.data # = ['data'] , 독립변수\n",
    "label = iris.target # 종속변수\n",
    "\n",
    "print('붓꽃 데이터 세트 크기 ', features.shape, label.shape)\n",
    "model = DecisionTreeClassifier(random_state=156)\n",
    "model\n",
    "\n",
    "# 5개의 폴드세트로 분리하는 KFold 객체를 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "print(kfold)\n",
    "\n",
    "for train_idx, test_idx in kfold.split(features):\n",
    "    print('train \\n', train_idx)\n",
    "    print('test \\n', test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 교차 검증 정확도 : 1.0 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#1 검증 세트 인덱스 : [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29] \n",
      "\n",
      "#2 교차 검증 정확도 : 0.9667 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#2 검증 세트 인덱스 : [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59] \n",
      "\n",
      "#3 교차 검증 정확도 : 0.8667 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#3 검증 세트 인덱스 : [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89] \n",
      "\n",
      "#4 교차 검증 정확도 : 0.9333 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#4 검증 세트 인덱스 : [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] \n",
      "\n",
      "#5 교차 검증 정확도 : 0.7333 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#5 검증 세트 인덱스 : [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "## 교차 검증별 정확도  [1.     0.9667 0.8667 0.9333 0.7333]\n",
      "## 교차 검증별 정확도 평균  0.9\n"
     ]
    }
   ],
   "source": [
    "# 폴드 세트별 정확도 점수를 저장할 리스트 객체 선언\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "# KFold의 split() 함수를 호출하면 폴드명 학습용, 검증용 데이터의 row index를 array로 반환\n",
    "for train_idx, test_idx in kfold.split(features):\n",
    "    # 훈련데이터와 검증데이터 추출\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = label[train_idx], label[test_idx]\n",
    "    # 학습 및 예측\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    # 예측점수 확인을 위해서 accuracy_score() 함수 사용\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print(f'#{n_iter} 교차 검증 정확도 : {accuracy} | 학습데이터크기 : {train_size} | 검증데이터 크기 : {test_size}')\n",
    "    print(f'#{n_iter} 검증 세트 인덱스 : {test_idx} \\n')\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('## 교차 검증별 정확도 ', np.round(cv_accuracy, 4))\n",
    "print('## 교차 검증별 정확도 평균 ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Stratified K-Fold\n",
    "* 학습데이터와 검증데이터 세트가 가지는 레이블(종속변수)의 분포도가 유사하도록 검증데이터를 추출하는 방법\n",
    "* 일반 K-Fold와 다르게 레이블(종속변수)값을 넣어서 균형적으로 분할되도록 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    50\n",
      "1    50\n",
      "0    50\n",
      "Name: label, dtype: int64\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "print(iris_df.label.value_counts())\n",
    "print(iris_df['label'].iloc[0])\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train  [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "#1 학습 데이터 레이블 분포 \n",
      " 2    50\n",
      "1    50\n",
      "0    20\n",
      "Name: label, dtype: int64\n",
      "#1 검증 데이터 레이블 분포 \n",
      " 0    30\n",
      "Name: label, dtype: int64\n",
      "train  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test  [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "#2 학습 데이터 레이블 분포 \n",
      " 2    50\n",
      "1    40\n",
      "0    30\n",
      "Name: label, dtype: int64\n",
      "#2 검증 데이터 레이블 분포 \n",
      " 0    20\n",
      "1    10\n",
      "Name: label, dtype: int64\n",
      "train  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test  [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "#3 학습 데이터 레이블 분포 \n",
      " 2    50\n",
      "0    50\n",
      "1    20\n",
      "Name: label, dtype: int64\n",
      "#3 검증 데이터 레이블 분포 \n",
      " 1    30\n",
      "Name: label, dtype: int64\n",
      "train  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "test  [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "#4 학습 데이터 레이블 분포 \n",
      " 0    50\n",
      "1    40\n",
      "2    30\n",
      "Name: label, dtype: int64\n",
      "#4 검증 데이터 레이블 분포 \n",
      " 2    20\n",
      "1    10\n",
      "Name: label, dtype: int64\n",
      "train  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "test  [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "#5 학습 데이터 레이블 분포 \n",
      " 1    50\n",
      "0    50\n",
      "2    20\n",
      "Name: label, dtype: int64\n",
      "#5 검증 데이터 레이블 분포 \n",
      " 2    30\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 일반 K-Fold 방식을 사용해서 레이블 분포를 확인\n",
    "kfold = KFold(n_splits=5)\n",
    "n_iter = 0\n",
    "for train_idx, test_idx in kfold.split(iris_df):\n",
    "    print('train ', train_idx)\n",
    "    print('test ', test_idx)\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_idx]\n",
    "    label_test = iris_df['label'].iloc[test_idx]\n",
    "    print(f'#{n_iter} 학습 데이터 레이블 분포 \\n {label_train.value_counts()}')\n",
    "    print(f'#{n_iter} 검증 데이터 레이블 분포 \\n {label_test.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 학습 데이터 레이블 분포 \n",
      " 2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "#1 검증 데이터 레이블 분포 \n",
      " 2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "#2 학습 데이터 레이블 분포 \n",
      " 2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "#2 검증 데이터 레이블 분포 \n",
      " 2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "#3 학습 데이터 레이블 분포 \n",
      " 2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "#3 검증 데이터 레이블 분포 \n",
      " 2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "#4 학습 데이터 레이블 분포 \n",
      " 2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "#4 검증 데이터 레이블 분포 \n",
      " 2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "#5 학습 데이터 레이블 분포 \n",
      " 2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: label, dtype: int64\n",
      "#5 검증 데이터 레이블 분포 \n",
      " 2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# StratifiedKFold 방식을 사용해서 레이블 분포를 확인하기\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)\n",
    "n_iter = 0\n",
    "\n",
    "for train_idx, test_idx in skfold.split(iris_df, iris_df.label):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_idx]\n",
    "    label_test = iris_df['label'].iloc[test_idx]\n",
    "    print(f'#{n_iter} 학습 데이터 레이블 분포 \\n {label_train.value_counts()}')\n",
    "    print(f'#{n_iter} 검증 데이터 레이블 분포 \\n {label_test.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 교차 검증 정확도 : 0.9667 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#1 검증 세트 인덱스 : [  0   1   2   3   4   5   6   7   8   9  50  51  52  53  54  55  56  57\n",
      "  58  59 100 101 102 103 104 105 106 107 108 109] \n",
      "\n",
      "#2 교차 검증 정확도 : 0.9667 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#2 검증 세트 인덱스 : [ 10  11  12  13  14  15  16  17  18  19  60  61  62  63  64  65  66  67\n",
      "  68  69 110 111 112 113 114 115 116 117 118 119] \n",
      "\n",
      "#3 교차 검증 정확도 : 0.9 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#3 검증 세트 인덱스 : [ 20  21  22  23  24  25  26  27  28  29  70  71  72  73  74  75  76  77\n",
      "  78  79 120 121 122 123 124 125 126 127 128 129] \n",
      "\n",
      "#4 교차 검증 정확도 : 0.9667 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#4 검증 세트 인덱스 : [ 30  31  32  33  34  35  36  37  38  39  80  81  82  83  84  85  86  87\n",
      "  88  89 130 131 132 133 134 135 136 137 138 139] \n",
      "\n",
      "#5 교차 검증 정확도 : 1.0 | 학습데이터크기 : 120 | 검증데이터 크기 : 30\n",
      "#5 검증 세트 인덱스 : [ 40  41  42  43  44  45  46  47  48  49  90  91  92  93  94  95  96  97\n",
      "  98  99 140 141 142 143 144 145 146 147 148 149] \n",
      "\n",
      "## 교차 검증별 정확도  [0.9667 0.9667 0.9    0.9667 1.    ]\n",
      "## 교차 검증별 정확도 평균  0.96002\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=156)\n",
    "skfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 폴드 세트별 정확도 점수를 저장할 리스트 객체 선언\n",
    "cv_accuracy = []\n",
    "n_iter = 0\n",
    "\n",
    "# KFold의 split() 함수를 호출하면 폴드명 학습용, 검증용 데이터의 row index를 array로 반환\n",
    "for train_idx, test_idx in skfold.split(features, label):\n",
    "    # 훈련데이터와 검증데이터 추출\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = label[train_idx], label[test_idx]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    n_iter += 1\n",
    "    \n",
    "    # 예측점수 확인을 위해서 accuracy_score() 함수 사용\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    \n",
    "    print(f'#{n_iter} 교차 검증 정확도 : {accuracy} | 학습데이터크기 : {train_size} | 검증데이터 크기 : {test_size}')\n",
    "    print(f'#{n_iter} 검증 세트 인덱스 : {test_idx} \\n')\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('## 교차 검증별 정확도 ', np.round(cv_accuracy, 4))\n",
    "print('## 교차 검증별 정확도 평균 {: .5f}'.format(np.mean(cv_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. cross_val_score()\n",
    "* cross_val_score는 K-Fold 사용할 때 수행했던 3단계의 교차검증을 보다 간편하게 해주는 방법\n",
    "* cross_val_score() 함수는 폴드세트, 학습 및 예측, 평가를 한번에 수행해 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세트별 교차 검증 정확도 [0.9667 0.9667 0.9    0.9667 1.    ]\n",
      "교차 검증 정확도의 평균0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "scores = cross_val_score(model, features, label, scoring='accuracy', cv=5)\n",
    "print(f'세트별 교차 검증 정확도 {np.round(scores,4)}')\n",
    "print(f'교차 검증 정확도의 평균{np.round(np.mean(scores),4)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. GridSearchCV\n",
    "* Model을 생성할 때 인자로 주어지는 파라미터를 Hyper Parameter 라고 한다.\n",
    "* 예측도 높이기위해서 Hyper Parameter Tunning이 필요\n",
    "* GridSearchCV는 parameter를 여러개 다르게 설정한 모델을 만들어서 성능의 비교를 통해서 최적의 파라미터를 찾아주고, \n",
    "  교차검증도 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.052705</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.052705</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.000799      0.000399         0.000200        0.000399   \n",
       "1       0.000399      0.000488         0.000399        0.000489   \n",
       "2       0.000600      0.000490         0.000199        0.000399   \n",
       "3       0.000590      0.000483         0.000211        0.000421   \n",
       "4       0.000000      0.000000         0.000591        0.000483   \n",
       "5       0.000797      0.000398         0.000398        0.000488   \n",
       "\n",
       "  param_max_depth param_min_samples_split  \\\n",
       "0               1                       2   \n",
       "1               1                       3   \n",
       "2               2                       2   \n",
       "3               2                       3   \n",
       "4               3                       2   \n",
       "5               3                       3   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}           0.666667   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}           0.666667   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}           0.875000   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}           0.875000   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}           0.958333   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}           0.958333   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.708333           0.708333           0.708333           0.708333   \n",
       "1           0.708333           0.708333           0.708333           0.708333   \n",
       "2           1.000000           1.000000           1.000000           0.916667   \n",
       "3           1.000000           1.000000           1.000000           0.916667   \n",
       "4           1.000000           1.000000           1.000000           0.916667   \n",
       "5           1.000000           1.000000           1.000000           0.916667   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.700000        0.016667                5  \n",
       "1         0.700000        0.016667                5  \n",
       "2         0.958333        0.052705                3  \n",
       "3         0.958333        0.052705                3  \n",
       "4         0.975000        0.033333                1  \n",
       "5         0.975000        0.033333                1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=121)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# max_depth : 트리의 최대 깊이\n",
    "# min_samples_split : 노드를 분할하기 위한 최소한의 샘플데이터 수\n",
    "param_dict = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}\n",
    "\n",
    "# 하이퍼 파라미터들을 5개의 학습, 검증 폴드로 나누어서 수행\n",
    "# refit=True가 default 이고, True이면, 가장 좋은 파라미터로 설정하여 재 학습시킨다.\n",
    "grid_tree = GridSearchCV(model, param_grid=param_dict, cv=5, refit=True)\n",
    "print(type(grid_tree))\n",
    "\n",
    "# GridSearchCV 객체를 fit() 으로 학습하기\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "#print(grid_tree.cv_results_)\n",
    "grid_tree_df = pd.DataFrame(grid_tree.cv_results_)\n",
    "grid_tree_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적의 파라미터는 {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 예측 점수는 0.975\n",
      "검증 데이터 세트 정확도 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f'GridSearchCV 최적의 파라미터는 {grid_tree.best_params_}')\n",
    "print(f'GridSearchCV 최고 예측 점수는 {grid_tree.best_score_}')\n",
    "\n",
    "# GridSearchCV의 refit으로 재확습된 model 객체를 반환해준다.\n",
    "best_model = grid_tree.best_estimator_\n",
    "\n",
    "pred = best_model.predict(X_test)\n",
    "print(f'검증 데이터 세트 정확도 {accuracy_score(y_test, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
